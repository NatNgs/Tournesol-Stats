{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution\n",
    "\n",
    "Compute random graphs and statistics from multiple tournesol datasets of different dates to compare them\n",
    "\n",
    "## 1. Init or update Tournesol dataset (Todo once every week)\n",
    "\n",
    "- Download zip from https://api.tournesol.app/exports/all/\n",
    "- Extract zip\n",
    "\t- Recommended to do so in directories names with the week date like: `tournesol_dataset_2023-12-31/`\n",
    "\n",
    "## 2. Init or update Youtube cache (if tournesol dataset was updated)\n",
    "\n",
    "Run script `py src/rndstats.py (-t <latest TOURNESOL_DATASET_PATH>) (-c <YTDATA_CACHE_PATH>) --fetch`\n",
    "\n",
    "## 3. Check and update Notebook variables\n",
    "\n",
    "See bloc [2] below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import html\n",
    "import glob\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import matplotlib.dates as mtdt\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Ensure notebook is running from Tournesol-Stats dir\n",
    "_pwd = os.path.realpath('.').split(os.sep)\n",
    "if 'src' in _pwd:\n",
    "\twhile _pwd[-1] != 'src':\n",
    "\t\t_pwd.pop()\n",
    "\t_pwd.pop() # Go up from src dir to Tournesol-Stats\n",
    "\tos.chdir(os.sep.join(_pwd))\n",
    "print(os.path.realpath('.'))\n",
    "\n",
    "# Local project requirements\n",
    "sys.path.append('src/py')\n",
    "from dao.youtube_api import YoutubeAPI\n",
    "from model.tournesol_dataset.users import extractAllTournesolUsers, TournesolUser\n",
    "from model.tournesol_dataset.comparisons import ComparisonFile, ComparisonLine\n",
    "from model.tournesol_dataset.collectivecriteriascores import CollectiveCriteriaScoresFile\n",
    "from model.tournesol_dataset.individualcriteriascores import IndividualCriteriaScoresFile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook Variables\n",
    "TOURNESOL_DATASETS_PARENT_PATH='./data/' # Expecting data files located into: <TOURNESOL_DATASETS_PARENT_PATH>/**/<TOURNESOL_DATASET_PATH_FORMAT>\n",
    "TOURNESOL_DATASET_FILE_FORMAT=r'.*[/\\\\]tournesol_dataset_([0-9]{4}-[0-9]{2}-[0-9]{2}).zip$' # SHOULD END in \"yyyy-mm-dd\"\n",
    "YTDATA_CACHE_PATH='./data/YTData_cache.json.gz' ## TODO: DEPRECATED - Use youtubeAPI instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TOURNESOL_DATASET_PATHS: dict[str, str]={} # date: path\n",
    "for filename in glob.iglob(TOURNESOL_DATASETS_PARENT_PATH + '**/*.zip', recursive=True):\n",
    "\tmatch = re.match(TOURNESOL_DATASET_FILE_FORMAT, filename)\n",
    "\tif match:\n",
    "\t\tTOURNESOL_DATASET_PATHS[match.group(1)] = os.path.abspath(filename)\n",
    "\n",
    "DATE_MAP = {s: datetime.strptime(s, '%Y-%m-%d').date() for s in TOURNESOL_DATASET_PATHS}\n",
    "SORTED_DATES = sorted((k,v) for (k,v) in DATE_MAP.items())\n",
    "LAST = SORTED_DATES[-1][0]\n",
    "print('Dataset snapshots found:', len(TOURNESOL_DATASET_PATHS), f\"(from {min(TOURNESOL_DATASET_PATHS.keys())} to {max(TOURNESOL_DATASET_PATHS.keys())})\")\n",
    "\n",
    "# Data files\n",
    "USERS:set[TournesolUser] = extractAllTournesolUsers(TOURNESOL_DATASET_PATHS[LAST])\n",
    "COMPARISONS:dict[str,ComparisonFile] = dict()\n",
    "COLLECTIVE_SCORES:dict[str,CollectiveCriteriaScoresFile] = dict()\n",
    "INDIVIDUAL_SCORES:dict[str,IndividualCriteriaScoresFile] = dict()\n",
    "for date in TOURNESOL_DATASET_PATHS:\n",
    "\tCOMPARISONS[date] = ComparisonFile(TOURNESOL_DATASET_PATHS[date])\n",
    "\tCOLLECTIVE_SCORES[date] = CollectiveCriteriaScoresFile(TOURNESOL_DATASET_PATHS[date])\n",
    "\tINDIVIDUAL_SCORES[date] = IndividualCriteriaScoresFile(TOURNESOL_DATASET_PATHS[date])\n",
    "\n",
    "# Youtube Data\n",
    "YTDATA = YoutubeAPI()\n",
    "try:\n",
    "\tYTDATA.load(YTDATA_CACHE_PATH)\n",
    "except FileNotFoundError as e:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Users impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users ranked by how much their scores changed between last 2 weeks\n",
    "\n",
    "print(\"Score difference from\", SORTED_DATES[-2][0], \"to\", SORTED_DATES[-1][0])\n",
    "\n",
    "week1_scores = INDIVIDUAL_SCORES[SORTED_DATES[-2][0]].get_scores(criterion='largely_recommended') # [user][vid][crit] = (score, unc.)\n",
    "vids = {vid for v in week1_scores.values() for vid in v}\n",
    "week2_scores = INDIVIDUAL_SCORES[SORTED_DATES[-1][0]].get_scores(users=week1_scores.keys(), vids=vids) # [user][vid][crit] = (score, unc.)\n",
    "\n",
    "users_weekscores: dict[str,list[float]] = dict() # users_weekscores[user] = [upd. score]\n",
    "for usr in week1_scores:\n",
    "\tif len(week1_scores[usr]) < 10:\n",
    "\t\tcontinue\n",
    "\tuser_weekscores = list()\n",
    "\tfor vid in week1_scores[usr]:\n",
    "\t\tfor crit in week1_scores[usr][vid]:\n",
    "\t\t\tif usr in week2_scores and vid in week2_scores[usr] and crit in week2_scores[usr][vid]:\n",
    "\t\t\t\tuser_weekscores.append(abs(week2_scores[usr][vid][crit][0]-week1_scores[usr][vid][crit][0]))\n",
    "\tusers_weekscores[usr] = user_weekscores\n",
    "\n",
    "sorted_users = sorted(users_weekscores.keys(), key=lambda usr: sum(users_weekscores[usr]), reverse=True)\n",
    "\n",
    "print('  user             sum     avg  median    max')\n",
    "print('---------------  -----  ------  ------  -----')\n",
    "for user in sorted_users[:10]:\n",
    "\tprint(f\"{user[:15]:<15}  {sum(users_weekscores[user]):5.0f}  {np.average(users_weekscores[user]):6.2f}  {np.quantile(users_weekscores[user],0.5):6.2f}  {max(users_weekscores[user]):5.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users ranked by how much the score of their comparisons changed between last 2 weeks\n",
    "\n",
    "def users_impact(datemin:str, datemax:str):\n",
    "\tMIN_TRUST_SCORE = 0.01 # Add this value to all trust scores to account for users with 0 trust score (to be improved by retroengineering trust algorithm, see https://arxiv.org/pdf/2211.01179.pdf)\n",
    "\n",
    "\t# Users to consider\n",
    "\tusers_last_week_comparisons: dict[str,set[str]] = dict()# [user] = {vid, ...}\n",
    "\tdef extractVids(line:ComparisonLine):\n",
    "\t\tif line.criterion == 'largely_recommended' and line.date >= datemin and line.date < datemax:\n",
    "\t\t\tuser_set = users_last_week_comparisons.setdefault(line.user,set())\n",
    "\t\t\tuser_set.add(line.vid1)\n",
    "\t\t\tuser_set.add(line.vid2)\n",
    "\tCOMPARISONS[LAST].foreach(extractVids)\n",
    "\tusers = set(users_last_week_comparisons.keys())\n",
    "\n",
    "\t# Users trust score\n",
    "\ttrust_scores = {u.public_username: u.trust_score + MIN_TRUST_SCORE for u in USERS if u.public_username in users}\n",
    "\n",
    "\t# Individual scores differences\n",
    "\tweek1_scores = INDIVIDUAL_SCORES[datemin].get_scores(users=users, criterion='largely_recommended') # [user][vid][crit] = (score, unc.)\n",
    "\tweek2_scores = INDIVIDUAL_SCORES[datemax].get_scores(users=users, criterion='largely_recommended') # [user][vid][crit] = (score, unc.)\n",
    "\tweighted_indiv_diff = dict()\n",
    "\tfor u in users:\n",
    "\t\tif not (u in week1_scores and u in week2_scores and u in trust_scores):\n",
    "\t\t\tcontinue\n",
    "\t\tweighted_diff = {\n",
    "\t\t\tv: (week2_scores[u][v]['largely_recommended'][0]-week1_scores[u][v]['largely_recommended'][0])*trust_scores[u]\n",
    "\t\t\tfor v in set(week1_scores[u].keys()).intersection(week2_scores[u].keys()) \n",
    "\t\t}\n",
    "\t\tweighted_indiv_diff[u] = weighted_diff\n",
    "\n",
    "\t# Collective scores differences\n",
    "\tweek1_scores = COLLECTIVE_SCORES[datemin].get_scores(criterion='largely_recommended') # [vid][crit] = (score, unc.)\n",
    "\tweek2_scores = COLLECTIVE_SCORES[datemax].get_scores(criterion='largely_recommended') # [vid][crit] = (score, unc.)\n",
    "\tcoll_diff = {v: week2_scores[v]['largely_recommended'][0]-week1_scores[v]['largely_recommended'][0] for v in week1_scores if v in week2_scores}\n",
    "\n",
    "\t# Decompose collective scores differences from individual scores\n",
    "\timpact_from_users:dict[str,dict[str,float]] = dict() # [user][vid] = collectiveimpact\n",
    "\timpact_on_videos:dict[str,dict[str,float]] = dict() # [vid][user] = collectiveimpact (such as sum of [vid].values() == coll_diff[vid])\n",
    "\tfor v in coll_diff:\n",
    "\t\tif coll_diff[v] < 0.1: # Ignore low changes\n",
    "\t\t\tcontinue\n",
    "\t\ttotal_impact = 0\n",
    "\t\tusers_impact = {} # [user] = individualimpact (value between -220 and +220, most of the time will be around 0)\n",
    "\t\tfor u in weighted_indiv_diff:\n",
    "\t\t\tif not v in weighted_indiv_diff[u]:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tusers_impact[u] = weighted_indiv_diff[u][v]\n",
    "\t\t\ttotal_impact += weighted_indiv_diff[u][v]\n",
    "\t\t\n",
    "\t\t# Controls to prevent errors\n",
    "\t\tif abs(total_impact) < 0.01: # No (or almost no) impact found, ignore\n",
    "\t\t\t# print(f\"Failed to compute impact for {v}: Collective score change is {coll_diff[v]:.2f} but cumulated individual change is negligeable ({total_impact})\")\n",
    "\t\t\tcontinue\n",
    "\t\tif np.sign(total_impact) != np.sign(coll_diff[v]):\n",
    "\t\t\t# print(f\"Failed to compute impact for {v}: Collective score change is {coll_diff[v]:.2f} but cumulated individual change is {total_impact:.2f}\")\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# Compute every user impact (dividing total impact by collective score change)\n",
    "\t\timpact_on_videos[v] = dict()\n",
    "\t\tfor u in users_impact:\n",
    "\t\t\tcoll_impact = users_impact[u]/total_impact * coll_diff[v]\n",
    "\t\t\timpact_on_videos[v][u] = coll_impact\n",
    "\t\t\timpact_from_users.setdefault(u, dict())[v] = coll_impact\n",
    "\t\n",
    "\n",
    "\n",
    "\t# Sum users absolute impact, and print top 10\n",
    "\tdef print_user_impact(u, maximpacted=5):\n",
    "\t\tsorted_impact = [v for v in sorted(impact_from_users[u], key=lambda v: abs(impact_from_users[u][v]), reverse=True) if abs(impact_from_users[u][v] >= 0.05)]\n",
    "\t\tpositiveimpact = sum(s for s in impact_from_users[u].values() if s > 0)\n",
    "\t\tnegativeimpact = -sum(s for s in impact_from_users[u].values() if s < 0)\n",
    "\t\tprint(\n",
    "\t\t\tf\"- {u} impacted the score of {len(sorted_impact)} video{'s' if len(sorted_impact) != 1 else ''}\",\n",
    "\t\t\t(f\"(↗️{positiveimpact:.1f} ↘️{negativeimpact:.1f})\" if (positiveimpact > 0.05 and negativeimpact > 0.05) else (f\"(↗️{positiveimpact:.1f})\" if positiveimpact > 0.05 else f\"(↘️{negativeimpact:.1f})\"))\n",
    "\t\t)\n",
    "\t\tif maximpacted > 0:\n",
    "\t\t\tprint('    ', ', '.join(f\"{sorted_impact[i]} ({impact_from_users[u][sorted_impact[i]]:+.1f})\" for i in range(0, min(maximpacted, len(sorted_impact)))), '...' if len(sorted_impact) > maximpacted else '')\n",
    "\t\n",
    "\tdef print_video_impact(v, maximpacted=5):\n",
    "\t\tsorted_impact = [u for u in sorted(impact_on_videos[v], key=lambda u: abs(impact_on_videos[v][u]), reverse=True) if abs(impact_on_videos[v][u]) >= 0.05]\n",
    "\t\tpositiveimpact = sum(s for s in impact_on_videos[v].values() if s > 0)\n",
    "\t\tnegativeimpact = -sum(s for s in impact_on_videos[v].values() if s < 0)\n",
    "\t\tprint(\n",
    "\t\t\tf\"- {v}: Score {week1_scores[v]['largely_recommended'][0]:.1f} => {week2_scores[v]['largely_recommended'][0]:.1f} updated by {len(sorted_impact)} contributor{'s' if len(sorted_impact) != 1 else ''}\",\n",
    "\t\t\t(f\"(↗️{positiveimpact:.1f} ↘️{negativeimpact:.1f})\" if (positiveimpact > 0.05 and negativeimpact > 0.05) else (f\"(↗️{positiveimpact:.1f})\" if positiveimpact > 0.05 else f\"(↘️{negativeimpact:.1f})\"))\n",
    "\t\t)\n",
    "\t\tif maximpacted > 0:\n",
    "\t\t\tprint('    ', ', '.join(f\"{sorted_impact[i]} ({impact_on_videos[v][sorted_impact[i]]:+.1f})\" for i in range(0, min(maximpacted, len(sorted_impact)))), '...' if len(sorted_impact) > maximpacted else '')\n",
    "\n",
    "\tprint()\n",
    "\tprint('User impacts:')\n",
    "\tcumulated_user_impact = {u: np.sum(np.abs(list(impact_from_users[u].values()))) for u in impact_from_users}\n",
    "\tfor u in sorted(cumulated_user_impact, key=cumulated_user_impact.get, reverse=True)[:20]:\n",
    "\t\tprint_user_impact(u, 0)\n",
    "\t\tif u == 'NatNgs':\n",
    "\t\t\tbreak\n",
    "\tprint()\n",
    "\tprint('Most impacted recommended videos:')\n",
    "\tcumulated_video_impact = {v: np.sum(np.abs(list(impact_on_videos[v].values())))\n",
    "\t\tfor v in impact_on_videos\n",
    "\t\tif week1_scores[v]['largely_recommended'][0] >= 20\n",
    "\t\tor week2_scores[v]['largely_recommended'][0] >= 20\n",
    "\t}\n",
    "\tfor v in sorted(cumulated_video_impact, key=cumulated_video_impact.get, reverse=True)[:20]:\n",
    "\t\tprint_video_impact(v, 0)\n",
    "\n",
    "\tprint()\n",
    "\n",
    "users_impact(SORTED_DATES[-2][0], SORTED_DATES[-1][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top & growing\n",
    "\n",
    "prev_scores = None\n",
    "for d,_ in SORTED_DATES:\n",
    "\tscores = COLLECTIVE_SCORES[d].get_scores(criterion='largely_recommended') # (score, uncertainty) = allscores[video]['largely_recommended']\n",
    "\tif not prev_scores:\n",
    "\t\tprev_scores = scores\n",
    "\t\tcontinue\n",
    "\n",
    "\tfor vid in list(scores.keys()):\n",
    "\t\tif not vid in prev_scores:\n",
    "\t\t\tprev_scores[vid] = scores[vid]\n",
    "\t\n",
    "\tgrowth:list[tuple[float,str]] = list(map(lambda vid: (abs(scores[vid]['largely_recommended'][0] - prev_scores[vid]['largely_recommended'][0]), vid), scores.keys())) ## + & -\n",
    "\t#growth:list[tuple[float,str]] = list(map(lambda vid: (scores[vid]['largely_recommended'][0] - prev_scores[vid]['largely_recommended'][0], vid), scores.keys())) ## Growing only\n",
    "\t#growth:list[tuple[float,str]] = list(map(lambda vid: (prev_scores[vid]['largely_recommended'][0] - scores[vid]['largely_recommended'][0], vid), scores.keys())) ## Falling only\n",
    "\tgrowth.sort(reverse=True)\n",
    "\n",
    "\tprint('Week ' + d)\n",
    "\tfor i in range(10):\n",
    "\t\tvid = growth[i][1]\n",
    "\t\tprev = prev_scores[vid]['largely_recommended'][0]\n",
    "\t\tnews = scores[vid]['largely_recommended'][0]\n",
    "\t\tif news > prev:\n",
    "\t\t\tprint(f\"{i+1:2d}: ({prev:+3.0f} => {news:+3.0f} ↗{growth[i][0]:4.1f})\", YTDATA.videos.get(vid, vid))\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"{i+1:2d}: ({prev:+3.0f} => {news:+3.0f} ↘{growth[i][0]:4.1f})\", YTDATA.videos.get(vid, vid))\n",
    "\tprint()\n",
    "\tprev_scores = scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = 'NatNgs'\n",
    "\n",
    "## Video score over time (part 1)\n",
    "# Plot lines: one line per video (opacity: number of users having compared the video - 1=0%..10+=100%)\n",
    "# x axis: Number of others videos it has been compared with\n",
    "# y axis: Score (-100 to +100)\n",
    "\n",
    "# Fetch scores\n",
    "vid_date_vals:dict[str,dict[str,tuple[int,int,float]]] = dict() # vid_date_vals[vid][date] = (users,vid_cmps,score)\n",
    "max_cmps = 0\n",
    "max_usrs = 0\n",
    "\n",
    "def fetch_collective_scores():\n",
    "\tvid_date_data:dict[str,dict[str,tuple[set[str],set[str]]]] = dict() # vid_date_data[vid][date] = (users,vid_cmps)\n",
    "\t# Fetch users & comparisons per date\n",
    "\tdef fetch_user_data(line: ComparisonLine):\n",
    "\t\tif line.criterion != 'largely_recommended':\n",
    "\t\t\treturn\n",
    "\t\tvid1_d = vid_date_data.setdefault(line.vid1, dict()).setdefault(line.date, (set(),set()))\n",
    "\t\tvid1_d[0].add(line.user)\n",
    "\t\tvid1_d[1].add(line.vid2)\n",
    "\t\tvid2_d = vid_date_data.setdefault(line.vid2, dict()).setdefault(line.date, (set(),set()))\n",
    "\t\tvid2_d[0].add(line.user)\n",
    "\t\tvid2_d[1].add(line.vid1)\n",
    "\tprint('Fetching Comparisons', end='')\n",
    "\tfor comparisons in COMPARISONS.values():\n",
    "\t\tprint('.', end='', flush=True)\n",
    "\t\tcomparisons.foreach(fetch_user_data)\n",
    "\tprint()\n",
    "\n",
    "\tprint('Fetching scores', end='')\n",
    "\tfor (date,collectivescore) in COLLECTIVE_SCORES.items():\n",
    "\t\tprint('.', end='', flush=True)\n",
    "\t\tscores = collectivescore.get_scores(criterion='largely_recommended', vids=vid_date_data.keys()) # (score,uncertainty) = out[vid]['largely_recommended']\n",
    "\t\tfor vid in scores:\n",
    "\t\t\tusrs = set()\n",
    "\t\t\tcmps = 0\n",
    "\t\t\tfor d in vid_date_data[vid]:\n",
    "\t\t\t\tif d <= date:\n",
    "\t\t\t\t\tusrs.update(vid_date_data[vid][d][0])\n",
    "\t\t\t\t\tcmps += len(vid_date_data[vid][d][1])\n",
    "\t\t\ts = scores[vid]['largely_recommended'][0]\n",
    "\n",
    "\t\t\t# Ignore if less than 3 users\n",
    "\t\t\tif len(usrs) < 3: continue\n",
    "\t\t\tif len(usrs) > max_usrs: max_usrs = len(usrs)\n",
    "\t\t\tif cmps > max_cmps: max_cmps = cmps\n",
    "\n",
    "\t\t\tvid_date_vals.setdefault(vid,dict())[date] = (len(usrs),cmps,s)\n",
    "\tprint()\n",
    "\treturn (max_usrs, max_cmps)\n",
    "\n",
    "def fetch_individual_scores():\n",
    "\n",
    "\tvid_date_data:dict[str,dict[str,set[str]]] = dict() # vid_date_data[vid][date] = vid_cmps\n",
    "\t# Fetch users & comparisons per date\n",
    "\tdef fetch_user_data(line: ComparisonLine):\n",
    "\t\tif line.criterion != 'largely_recommended' or line.user != USER:\n",
    "\t\t\treturn\n",
    "\t\tvid_date_data.setdefault(line.vid1, dict()).setdefault(line.date, set()).add(line.vid2)\n",
    "\t\tvid_date_data.setdefault(line.vid2, dict()).setdefault(line.date, set()).add(line.vid1)\n",
    "\tprint(f'Fetching {USER} Comparisons', end='')\n",
    "\tfor comparisons in COMPARISONS.values():\n",
    "\t\tprint('.', end='', flush=True)\n",
    "\t\tcomparisons.foreach(fetch_user_data)\n",
    "\tprint()\n",
    "\n",
    "\tmax_cmps = 0\n",
    "\tprint(f'Fetching {USER} scores', end='')\n",
    "\tfor (date,individualscores) in INDIVIDUAL_SCORES.items():\n",
    "\t\tprint('.', end='', flush=True)\n",
    "\t\tscores = individualscores.get_scores(criterion='largely_recommended', vids=vid_date_data.keys(), users=[USER])[USER] # (score,uncertainty) = out[vid]['largely_recommended']\n",
    "\t\tfor vid in scores:\n",
    "\t\t\tcmps = 0\n",
    "\t\t\tfor d in vid_date_data[vid]:\n",
    "\t\t\t\tif d <= date:\n",
    "\t\t\t\t\tcmps += len(vid_date_data[vid][d])\n",
    "\t\t\ts = scores[vid]['largely_recommended'][0]\n",
    "\n",
    "\t\t\tif cmps > max_cmps: max_cmps = cmps\n",
    "\n",
    "\t\t\tvid_date_vals.setdefault(vid,dict())[date] = (1,cmps,s)\n",
    "\tprint()\n",
    "\treturn (1,max_cmps)\n",
    "\n",
    "(max_usrs,max_cmps) = fetch_individual_scores() # fetch_collective_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Video score over time (part 2)\n",
    "print('Plotting...', end='\\r', flush=True)\n",
    "\n",
    "# Prepare plot\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(8, 6)\n",
    "# ax.set_ylabel('Collective largely_recommended score')\n",
    "ax.set_ylabel(f\"{USER} largely_recommended score\")\n",
    "ax.set_xlabel('Date')\n",
    "\n",
    "ax.grid(visible=True, which='major', axis='both', color='gray')\n",
    "ax.grid(visible=True, which='minor', axis='both', color='#eee')\n",
    "\n",
    "ax.set_ylim([-100, 100])\n",
    "ax.yaxis.set_ticks([-75,-50,-25,0,25,50,75])\n",
    "\n",
    "ax.set_xlim(xmin=SORTED_DATES[0][1], xmax=SORTED_DATES[-1][1])\n",
    "ax.xaxis.set_ticks([SORTED_DATES[i][1] for i in range(len(SORTED_DATES)-1, 0, -4) if SORTED_DATES[i][0] >= '2023-08-21'])\n",
    "ax.xaxis.set_ticks([s[1] for s in SORTED_DATES if s[0] >= '2023-08-21'], minor=True)\n",
    "ax.xaxis.set_major_formatter(mtdt.DateFormatter('%y-%m-%d'))\n",
    "#ax.set_xlim([0, max_usrs+1])\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_xlim([1, 10**math.ceil(math.log(max_usrs,10))])\n",
    "# ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "\n",
    "# Plot lines\n",
    "n=0\n",
    "for (n,vid) in enumerate(vid_date_vals):\n",
    "\t# vid_date_vals[vid][date] = (users,vid_cmps,score)\n",
    "\txx = []\n",
    "\tyy = []\n",
    "\too = 0\n",
    "\tfor d in sorted(vid_date_vals[vid].keys()):\n",
    "\t\tdata = vid_date_vals[vid][d] #(users,vid_cmps,score)\n",
    "\t\tif d < '2023-08-21': continue\n",
    "\t\txx.append(DATE_MAP[d])\n",
    "\t\tyy.append(data[2])\n",
    "\t\too = data[0]\n",
    "\too = math.sqrt(oo) / math.sqrt(max_usrs)\n",
    "\n",
    "\t#if max(yy)-min(yy) >= 30:\n",
    "\tprint(f\"Plotting {n+1}/{len(vid_date_vals)}...   \", end='\\r', flush=True)\n",
    "\t\n",
    "\trgbcolor = colorsys.hsv_to_rgb(0 if yy[-1] < yy[0] else 0.3, 0.8, min(1,(max(yy)-min(yy))/25))\n",
    "\thexcolor = \"\".join(\"%02X\" % round(i*255) for i in rgbcolor)\n",
    "\tax.plot(xx, yy, linewidth=1, color=\"#\" + hexcolor + hexcolor[-2:]) # color='#0261'\n",
    "\t\t#if xx[-1] > 18:\n",
    "\t\t#ax.text(xx[-1], yy[-1], s=YTDATA.videos.get(vid,vid), horizontalalignment='left', verticalalignment='center', fontsize=6)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
